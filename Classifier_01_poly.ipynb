{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtSOa29est/wfMIQShLf3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Addykohli/Simple_Polynomial_classifier/blob/main/Classifier_01_poly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-er9j6BAWyUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSGhlwE0wVJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2835ef-ab3b-49d3-c166-8c89e1789cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90, Loss: 58.7999, Accuracy: 0.5797\n",
            "Epoch 2/90, Loss: 40.8563, Accuracy: 0.6915\n",
            "Epoch 3/90, Loss: 31.9947, Accuracy: 0.7552\n",
            "Epoch 4/90, Loss: 26.5567, Accuracy: 0.7893\n",
            "Epoch 5/90, Loss: 21.2030, Accuracy: 0.8742\n",
            "Epoch 6/90, Loss: 15.7561, Accuracy: 0.9200\n",
            "Epoch 7/90, Loss: 11.9864, Accuracy: 0.9425\n",
            "Epoch 8/90, Loss: 9.6433, Accuracy: 0.9547\n",
            "Epoch 9/90, Loss: 8.0615, Accuracy: 0.9607\n",
            "Epoch 10/90, Loss: 6.9626, Accuracy: 0.9685\n",
            "Epoch 11/90, Loss: 6.0921, Accuracy: 0.9758\n",
            "Epoch 12/90, Loss: 5.4645, Accuracy: 0.9792\n",
            "Epoch 13/90, Loss: 5.0180, Accuracy: 0.9810\n",
            "Epoch 14/90, Loss: 4.5765, Accuracy: 0.9852\n",
            "Epoch 15/90, Loss: 4.3029, Accuracy: 0.9845\n",
            "Epoch 16/90, Loss: 4.0164, Accuracy: 0.9862\n",
            "Epoch 17/90, Loss: 3.7734, Accuracy: 0.9860\n",
            "Epoch 18/90, Loss: 3.5579, Accuracy: 0.9870\n",
            "Epoch 19/90, Loss: 3.3499, Accuracy: 0.9890\n",
            "Epoch 20/90, Loss: 3.2011, Accuracy: 0.9900\n",
            "Epoch 21/90, Loss: 3.0916, Accuracy: 0.9888\n",
            "Epoch 22/90, Loss: 2.9435, Accuracy: 0.9895\n",
            "Epoch 23/90, Loss: 2.8122, Accuracy: 0.9898\n",
            "Epoch 24/90, Loss: 2.7777, Accuracy: 0.9902\n",
            "Epoch 25/90, Loss: 2.6843, Accuracy: 0.9892\n",
            "Epoch 26/90, Loss: 2.5207, Accuracy: 0.9900\n",
            "Epoch 27/90, Loss: 2.4528, Accuracy: 0.9920\n",
            "Epoch 28/90, Loss: 2.3332, Accuracy: 0.9920\n",
            "Epoch 29/90, Loss: 2.3149, Accuracy: 0.9935\n",
            "Epoch 30/90, Loss: 2.2020, Accuracy: 0.9932\n",
            "Epoch 31/90, Loss: 2.2145, Accuracy: 0.9908\n",
            "Epoch 32/90, Loss: 2.0922, Accuracy: 0.9930\n",
            "Epoch 33/90, Loss: 2.0417, Accuracy: 0.9940\n",
            "Epoch 34/90, Loss: 1.9777, Accuracy: 0.9940\n",
            "Epoch 35/90, Loss: 1.9933, Accuracy: 0.9935\n",
            "Epoch 36/90, Loss: 1.9398, Accuracy: 0.9932\n",
            "Epoch 37/90, Loss: 1.8684, Accuracy: 0.9945\n",
            "Epoch 38/90, Loss: 1.8477, Accuracy: 0.9935\n",
            "Epoch 39/90, Loss: 1.7480, Accuracy: 0.9952\n",
            "Epoch 40/90, Loss: 1.7826, Accuracy: 0.9940\n",
            "Epoch 41/90, Loss: 1.6678, Accuracy: 0.9952\n",
            "Epoch 42/90, Loss: 1.6769, Accuracy: 0.9945\n",
            "Epoch 43/90, Loss: 1.6423, Accuracy: 0.9955\n",
            "Epoch 44/90, Loss: 1.5711, Accuracy: 0.9965\n",
            "Epoch 45/90, Loss: 1.5857, Accuracy: 0.9942\n",
            "Epoch 46/90, Loss: 1.5282, Accuracy: 0.9952\n",
            "Epoch 47/90, Loss: 1.5395, Accuracy: 0.9955\n",
            "Epoch 48/90, Loss: 1.4805, Accuracy: 0.9955\n",
            "Epoch 49/90, Loss: 1.4571, Accuracy: 0.9960\n",
            "Epoch 50/90, Loss: 1.4378, Accuracy: 0.9952\n",
            "Epoch 51/90, Loss: 1.4029, Accuracy: 0.9952\n",
            "Epoch 52/90, Loss: 1.4050, Accuracy: 0.9950\n",
            "Epoch 53/90, Loss: 1.3473, Accuracy: 0.9972\n",
            "Epoch 54/90, Loss: 1.3603, Accuracy: 0.9962\n",
            "Epoch 55/90, Loss: 1.2960, Accuracy: 0.9965\n",
            "Epoch 56/90, Loss: 1.3216, Accuracy: 0.9942\n",
            "Epoch 57/90, Loss: 1.2917, Accuracy: 0.9960\n",
            "Epoch 58/90, Loss: 1.3065, Accuracy: 0.9945\n",
            "Epoch 59/90, Loss: 1.2882, Accuracy: 0.9960\n",
            "Epoch 60/90, Loss: 1.2492, Accuracy: 0.9965\n",
            "Epoch 61/90, Loss: 1.1993, Accuracy: 0.9970\n",
            "Epoch 62/90, Loss: 1.1888, Accuracy: 0.9965\n",
            "Epoch 63/90, Loss: 1.2233, Accuracy: 0.9965\n",
            "Epoch 64/90, Loss: 1.1971, Accuracy: 0.9965\n",
            "Epoch 65/90, Loss: 1.1452, Accuracy: 0.9980\n",
            "Epoch 66/90, Loss: 1.1387, Accuracy: 0.9960\n",
            "Epoch 67/90, Loss: 1.1743, Accuracy: 0.9962\n",
            "Epoch 68/90, Loss: 1.0959, Accuracy: 0.9972\n",
            "Epoch 69/90, Loss: 1.1009, Accuracy: 0.9975\n",
            "Epoch 70/90, Loss: 1.1167, Accuracy: 0.9968\n",
            "Epoch 71/90, Loss: 1.0450, Accuracy: 0.9972\n",
            "Epoch 72/90, Loss: 1.0500, Accuracy: 0.9968\n",
            "Epoch 73/90, Loss: 1.0351, Accuracy: 0.9972\n",
            "Epoch 74/90, Loss: 1.0697, Accuracy: 0.9962\n",
            "Epoch 75/90, Loss: 0.9944, Accuracy: 0.9970\n",
            "Epoch 76/90, Loss: 1.0248, Accuracy: 0.9970\n",
            "Epoch 77/90, Loss: 0.9824, Accuracy: 0.9968\n",
            "Epoch 78/90, Loss: 1.0228, Accuracy: 0.9965\n",
            "Epoch 79/90, Loss: 0.9657, Accuracy: 0.9975\n",
            "Epoch 80/90, Loss: 0.9621, Accuracy: 0.9975\n",
            "Epoch 81/90, Loss: 0.9594, Accuracy: 0.9972\n",
            "Epoch 82/90, Loss: 0.9171, Accuracy: 0.9982\n",
            "Epoch 83/90, Loss: 0.9195, Accuracy: 0.9978\n",
            "Epoch 84/90, Loss: 0.9501, Accuracy: 0.9970\n",
            "Epoch 85/90, Loss: 0.8858, Accuracy: 0.9988\n",
            "Epoch 86/90, Loss: 0.9216, Accuracy: 0.9968\n",
            "Epoch 87/90, Loss: 0.9197, Accuracy: 0.9978\n",
            "Epoch 88/90, Loss: 0.8876, Accuracy: 0.9975\n",
            "Epoch 89/90, Loss: 0.8590, Accuracy: 0.9985\n",
            "Epoch 90/90, Loss: 0.8678, Accuracy: 0.9980\n",
            "Test Accuracy: 0.9920\n"
          ]
        }
      ],
      "source": [
        "# Generate pseudo-data for polynomials\n",
        "# a, b, c are randomly generated from a uniform distribution\n",
        "# Labels are determined based on the discriminant D = b^2 -4ac\n",
        "\n",
        "def generate_data(num_samples=5000):\n",
        "    a = np.random.uniform(-10, 10, num_samples)\n",
        "    b = np.random.uniform(-10, 10, num_samples)\n",
        "    c = np.random.uniform(-10, 10, num_samples)\n",
        "\n",
        "    discriminant = b**2 - 4*a*c\n",
        "    labels = np.where(discriminant > 0, 2, np.where(discriminant == 0, 1, 0))\n",
        "\n",
        "    data = np.column_stack((a, b, c))\n",
        "    return data.astype(np.float32), labels.astype(np.int64)\n",
        "\n",
        "# Create dataset\n",
        "N = 5000\n",
        "X, y = generate_data(N)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train, X_test = torch.tensor(X_train), torch.tensor(X_test)\n",
        "y_train, y_test = torch.tensor(y_train), torch.tensor(y_test)\n",
        "\n",
        "# Define the neural network\n",
        "class PolyClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PolyClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(3, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 3)  # 3 output classes\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model = PolyClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 90\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    permutation = torch.randperm(X_train.size(0))\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i in range(0, X_train.size(0), batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = X_train[indices], y_train[indices]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# Testing\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_accuracy = (test_predicted == y_test).sum().item() / y_test.size(0)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example polynomial prediction\n",
        "try_a, try_b, try_c = 5.0, 0, 0  # Example values\n",
        "test_input = torch.tensor([[try_a, try_b, try_c]], dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    prediction = model(test_input)\n",
        "    _, predicted_class = torch.max(prediction, 1)\n",
        "    print(f\"Predicted class for (a={try_a}, b={try_b}, c={try_c}): {predicted_class.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwObyJCESS1A",
        "outputId": "b455f64b-f95b-478b-9e32-133abc1e032d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for (a=5.0, b=0, c=0): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 100 samples for each class and compute accuracy separately\n",
        "\n",
        "def generate_fixed_data(class_label, num_samples=100):\n",
        "    if class_label == 0:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = np.random.uniform(1, 10, num_samples)\n",
        "    elif class_label == 1:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = (b ** 2) / (4 * a)\n",
        "    else:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = np.random.uniform(-10, -1, num_samples)\n",
        "\n",
        "    data = np.column_stack((a, b, c))\n",
        "    return torch.tensor(data, dtype=torch.float32), torch.full((num_samples,), class_label, dtype=torch.int64)\n",
        "\n",
        "for class_label in range(3):\n",
        "    test_data, true_labels = generate_fixed_data(class_label)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(test_data)\n",
        "        _, predicted_classes = torch.max(predictions, 1)\n",
        "    accuracy = (predicted_classes == true_labels).sum().item() / true_labels.size(0)\n",
        "    print(f\"Accuracy for class {class_label}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wu9qB8SWf7G",
        "outputId": "0c9eb15f-fbc9-44de-8ce9-78c4e4a70ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0: 0.9200\n",
            "Accuracy for class 1: 0.0000\n",
            "Accuracy for class 2: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis:**\n",
        "\n",
        "Random generated data lacks instances of the 1 root class, therefore totally lacks any accuracy. The probability of geting polynomials with 1 root is rare in random coefficients.\n",
        "\n",
        "This is a case where due to the trainig and testing data were similar, the accuracy seemed to be very high but was lacking the ability to predict an entire class\n"
      ],
      "metadata": {
        "id": "mI1r-7G0WwbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**\n",
        "\n",
        "Generating data to ensure rare instances of 1 root polynomials"
      ],
      "metadata": {
        "id": "44GoaCB4XEhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate balanced data with 2000 samples per class\n",
        "def generate_balanced_data_v2(samples_per_class=2000):\n",
        "    data_v2, labels_v2 = [], []\n",
        "\n",
        "    while len(data_v2) < samples_per_class:\n",
        "        a_v2, b_v2, c_v2 = np.random.uniform(-10, 10, 3)\n",
        "        discriminant_v2 = b_v2**2 - 4*a_v2*c_v2\n",
        "        if discriminant_v2 < 0:\n",
        "            data_v2.append([a_v2, b_v2, c_v2])\n",
        "            labels_v2.append(0)\n",
        "\n",
        "\n",
        "    while len(data_v2) < 2 * samples_per_class:\n",
        "      a_v2, b_v2, c_v2 = np.random.randint(-10, 10, 3)\n",
        "      a_v2, b_v2, c_v2 = float(a_v2), float(b_v2), float(c_v2)\n",
        "      discriminant_v2 = b_v2**2 - 4*a_v2*c_v2\n",
        "      if discriminant_v2 == 0:\n",
        "        data_v2.append([a_v2, b_v2, c_v2])\n",
        "        labels_v2.append(1)\n",
        "\n",
        "    while len(data_v2) < 3 * samples_per_class:\n",
        "        a_v2, b_v2, c_v2 = np.random.uniform(-10, 10, 3)\n",
        "        discriminant_v2 = b_v2**2 - 4*a_v2*c_v2\n",
        "        if discriminant_v2 > 0:\n",
        "            data_v2.append([a_v2, b_v2, c_v2])\n",
        "            labels_v2.append(2)\n",
        "\n",
        "    data_v2, labels_v2 = np.array(data_v2, dtype=np.float32), np.array(labels_v2, dtype=np.int64)\n",
        "    indices_v2 = np.random.permutation(len(data_v2))\n",
        "    return data_v2[indices_v2], labels_v2[indices_v2]\n",
        "\n",
        "# Create dataset\n",
        "X_v2, y_v2 = generate_balanced_data_v2(2000)\n",
        "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(X_v2, y_v2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_v2, X_test_v2 = torch.tensor(X_train_v2), torch.tensor(X_test_v2)\n",
        "y_train_v2, y_test_v2 = torch.tensor(y_train_v2), torch.tensor(y_test_v2)\n",
        "\n",
        "# Define the neural network\n",
        "class PolyClassifierV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PolyClassifierV2, self).__init__()\n",
        "        self.fc1_v2 = nn.Linear(3, 16)\n",
        "        self.fc2_v2 = nn.Linear(16, 8)\n",
        "        self.fc3_v2 = nn.Linear(8, 3)  # 3 output classes\n",
        "        self.relu_v2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu_v2(self.fc1_v2(x))\n",
        "        x = self.relu_v2(self.fc2_v2(x))\n",
        "        x = self.fc3_v2(x)\n",
        "        return x\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model_v2 = PolyClassifierV2()\n",
        "criterion_v2 = nn.CrossEntropyLoss()\n",
        "optimizer_v2 = optim.Adam(model_v2.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs_v2 = 90\n",
        "batch_size_v2 = 64\n",
        "\n",
        "for epoch_v2 in range(epochs_v2):\n",
        "    permutation_v2 = torch.randperm(X_train_v2.size(0))\n",
        "    epoch_loss_v2 = 0\n",
        "    correct_v2 = 0\n",
        "    total_v2 = 0\n",
        "\n",
        "    for i in range(0, X_train_v2.size(0), batch_size_v2):\n",
        "        indices_v2 = permutation_v2[i:i+batch_size_v2]\n",
        "        batch_x_v2, batch_y_v2 = X_train_v2[indices_v2], y_train_v2[indices_v2]\n",
        "\n",
        "        optimizer_v2.zero_grad()\n",
        "        outputs_v2 = model_v2(batch_x_v2)\n",
        "        loss_v2 = criterion_v2(outputs_v2, batch_y_v2)\n",
        "        loss_v2.backward()\n",
        "        optimizer_v2.step()\n",
        "\n",
        "        epoch_loss_v2 += loss_v2.item()\n",
        "        _, predicted_v2 = torch.max(outputs_v2, 1)\n",
        "        total_v2 += batch_y_v2.size(0)\n",
        "        correct_v2 += (predicted_v2 == batch_y_v2).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch_v2+1}/{epochs_v2}, Loss: {epoch_loss_v2:.4f}, Accuracy: {correct_v2/total_v2:.4f}\")\n",
        "\n",
        "# Testing\n",
        "with torch.no_grad():\n",
        "    test_outputs_v2 = model_v2(X_test_v2)\n",
        "    _, test_predicted_v2 = torch.max(test_outputs_v2, 1)\n",
        "    test_accuracy_v2 = (test_predicted_v2 == y_test_v2).sum().item() / y_test_v2.size(0)\n",
        "    print(f\"Test Accuracy: {test_accuracy_v2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HNSMoHpsXYhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a27797-3584-4177-f1e4-8425f5738130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90, Loss: 86.4292, Accuracy: 0.3837\n",
            "Epoch 2/90, Loss: 75.2253, Accuracy: 0.4842\n",
            "Epoch 3/90, Loss: 63.5846, Accuracy: 0.6083\n",
            "Epoch 4/90, Loss: 50.6124, Accuracy: 0.7473\n",
            "Epoch 5/90, Loss: 41.1722, Accuracy: 0.8333\n",
            "Epoch 6/90, Loss: 34.9639, Accuracy: 0.8812\n",
            "Epoch 7/90, Loss: 30.6224, Accuracy: 0.8979\n",
            "Epoch 8/90, Loss: 27.3851, Accuracy: 0.9033\n",
            "Epoch 9/90, Loss: 24.9358, Accuracy: 0.9121\n",
            "Epoch 10/90, Loss: 22.9396, Accuracy: 0.9125\n",
            "Epoch 11/90, Loss: 21.3061, Accuracy: 0.9167\n",
            "Epoch 12/90, Loss: 20.0679, Accuracy: 0.9231\n",
            "Epoch 13/90, Loss: 18.9499, Accuracy: 0.9263\n",
            "Epoch 14/90, Loss: 18.0271, Accuracy: 0.9256\n",
            "Epoch 15/90, Loss: 17.1576, Accuracy: 0.9304\n",
            "Epoch 16/90, Loss: 16.6030, Accuracy: 0.9313\n",
            "Epoch 17/90, Loss: 15.9862, Accuracy: 0.9331\n",
            "Epoch 18/90, Loss: 15.3102, Accuracy: 0.9350\n",
            "Epoch 19/90, Loss: 14.8357, Accuracy: 0.9392\n",
            "Epoch 20/90, Loss: 14.3777, Accuracy: 0.9413\n",
            "Epoch 21/90, Loss: 13.9216, Accuracy: 0.9429\n",
            "Epoch 22/90, Loss: 13.7520, Accuracy: 0.9402\n",
            "Epoch 23/90, Loss: 13.1157, Accuracy: 0.9448\n",
            "Epoch 24/90, Loss: 12.8632, Accuracy: 0.9475\n",
            "Epoch 25/90, Loss: 12.5613, Accuracy: 0.9477\n",
            "Epoch 26/90, Loss: 12.3703, Accuracy: 0.9481\n",
            "Epoch 27/90, Loss: 12.0267, Accuracy: 0.9498\n",
            "Epoch 28/90, Loss: 11.8029, Accuracy: 0.9506\n",
            "Epoch 29/90, Loss: 11.5465, Accuracy: 0.9502\n",
            "Epoch 30/90, Loss: 11.3522, Accuracy: 0.9513\n",
            "Epoch 31/90, Loss: 11.0249, Accuracy: 0.9529\n",
            "Epoch 32/90, Loss: 10.9947, Accuracy: 0.9537\n",
            "Epoch 33/90, Loss: 10.6836, Accuracy: 0.9569\n",
            "Epoch 34/90, Loss: 10.5157, Accuracy: 0.9548\n",
            "Epoch 35/90, Loss: 10.4387, Accuracy: 0.9558\n",
            "Epoch 36/90, Loss: 10.1413, Accuracy: 0.9579\n",
            "Epoch 37/90, Loss: 10.0499, Accuracy: 0.9573\n",
            "Epoch 38/90, Loss: 9.9111, Accuracy: 0.9583\n",
            "Epoch 39/90, Loss: 9.7524, Accuracy: 0.9571\n",
            "Epoch 40/90, Loss: 9.5984, Accuracy: 0.9594\n",
            "Epoch 41/90, Loss: 9.5768, Accuracy: 0.9590\n",
            "Epoch 42/90, Loss: 9.5419, Accuracy: 0.9594\n",
            "Epoch 43/90, Loss: 9.2376, Accuracy: 0.9596\n",
            "Epoch 44/90, Loss: 9.3846, Accuracy: 0.9596\n",
            "Epoch 45/90, Loss: 9.0981, Accuracy: 0.9596\n",
            "Epoch 46/90, Loss: 8.9991, Accuracy: 0.9594\n",
            "Epoch 47/90, Loss: 9.0207, Accuracy: 0.9625\n",
            "Epoch 48/90, Loss: 8.9428, Accuracy: 0.9627\n",
            "Epoch 49/90, Loss: 8.7233, Accuracy: 0.9615\n",
            "Epoch 50/90, Loss: 8.5578, Accuracy: 0.9635\n",
            "Epoch 51/90, Loss: 8.4902, Accuracy: 0.9629\n",
            "Epoch 52/90, Loss: 8.3571, Accuracy: 0.9648\n",
            "Epoch 53/90, Loss: 8.4080, Accuracy: 0.9640\n",
            "Epoch 54/90, Loss: 8.2518, Accuracy: 0.9652\n",
            "Epoch 55/90, Loss: 8.1542, Accuracy: 0.9642\n",
            "Epoch 56/90, Loss: 8.2099, Accuracy: 0.9644\n",
            "Epoch 57/90, Loss: 8.1352, Accuracy: 0.9652\n",
            "Epoch 58/90, Loss: 8.0105, Accuracy: 0.9660\n",
            "Epoch 59/90, Loss: 7.7955, Accuracy: 0.9681\n",
            "Epoch 60/90, Loss: 7.8635, Accuracy: 0.9658\n",
            "Epoch 61/90, Loss: 7.9053, Accuracy: 0.9679\n",
            "Epoch 62/90, Loss: 7.7033, Accuracy: 0.9665\n",
            "Epoch 63/90, Loss: 7.5993, Accuracy: 0.9671\n",
            "Epoch 64/90, Loss: 7.4841, Accuracy: 0.9677\n",
            "Epoch 65/90, Loss: 7.5594, Accuracy: 0.9681\n",
            "Epoch 66/90, Loss: 7.4075, Accuracy: 0.9683\n",
            "Epoch 67/90, Loss: 7.4687, Accuracy: 0.9690\n",
            "Epoch 68/90, Loss: 7.2868, Accuracy: 0.9685\n",
            "Epoch 69/90, Loss: 7.2874, Accuracy: 0.9694\n",
            "Epoch 70/90, Loss: 7.2742, Accuracy: 0.9685\n",
            "Epoch 71/90, Loss: 7.1348, Accuracy: 0.9698\n",
            "Epoch 72/90, Loss: 7.1239, Accuracy: 0.9706\n",
            "Epoch 73/90, Loss: 6.9777, Accuracy: 0.9715\n",
            "Epoch 74/90, Loss: 6.8916, Accuracy: 0.9712\n",
            "Epoch 75/90, Loss: 6.9247, Accuracy: 0.9710\n",
            "Epoch 76/90, Loss: 7.0629, Accuracy: 0.9708\n",
            "Epoch 77/90, Loss: 6.8711, Accuracy: 0.9719\n",
            "Epoch 78/90, Loss: 6.9533, Accuracy: 0.9700\n",
            "Epoch 79/90, Loss: 6.7438, Accuracy: 0.9723\n",
            "Epoch 80/90, Loss: 6.7131, Accuracy: 0.9729\n",
            "Epoch 81/90, Loss: 6.8702, Accuracy: 0.9719\n",
            "Epoch 82/90, Loss: 6.7822, Accuracy: 0.9721\n",
            "Epoch 83/90, Loss: 6.5258, Accuracy: 0.9727\n",
            "Epoch 84/90, Loss: 6.5389, Accuracy: 0.9738\n",
            "Epoch 85/90, Loss: 6.5825, Accuracy: 0.9738\n",
            "Epoch 86/90, Loss: 6.7364, Accuracy: 0.9731\n",
            "Epoch 87/90, Loss: 6.4678, Accuracy: 0.9731\n",
            "Epoch 88/90, Loss: 6.3860, Accuracy: 0.9750\n",
            "Epoch 89/90, Loss: 6.3113, Accuracy: 0.9742\n",
            "Epoch 90/90, Loss: 6.4093, Accuracy: 0.9744\n",
            "Test Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 100 samples for each class and compute accuracy separately\n",
        "\n",
        "def generate_fixed_data(class_label, num_samples=100):\n",
        "    if class_label == 0:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = np.random.uniform(1, 10, num_samples)\n",
        "    elif class_label == 1:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = (b ** 2) / (4 * a)\n",
        "    else:\n",
        "        a = np.random.uniform(1, 10, num_samples)\n",
        "        b = np.random.uniform(-10, 10, num_samples)\n",
        "        c = np.random.uniform(-10, -1, num_samples)\n",
        "\n",
        "    data = np.column_stack((a, b, c))\n",
        "    return torch.tensor(data, dtype=torch.float32), torch.full((num_samples,), class_label, dtype=torch.int64)\n",
        "\n",
        "for class_label in range(3):\n",
        "    test_data, true_labels = generate_fixed_data(class_label)\n",
        "    with torch.no_grad():\n",
        "        predictions = model_v2(test_data)\n",
        "        _, predicted_classes = torch.max(predictions, 1)\n",
        "    accuracy = (predicted_classes == true_labels).sum().item() / true_labels.size(0)\n",
        "    print(f\"Accuracy for class {class_label}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0db29b8-0e09-49b9-8744-707520b72c45",
        "id": "0UARKekRldCv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0: 0.8400\n",
            "Accuracy for class 1: 1.0000\n",
            "Accuracy for class 2: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy is improved significantly"
      ],
      "metadata": {
        "id": "WRoMzFGgnOuU"
      }
    }
  ]
}